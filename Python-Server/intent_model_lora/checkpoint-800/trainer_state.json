{
  "best_global_step": 800,
  "best_metric": 1.0,
  "best_model_checkpoint": "./intent_model_lora\\checkpoint-800",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 800,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0625,
      "grad_norm": 2.145233154296875,
      "learning_rate": 1.9591666666666667e-05,
      "loss": 0.6932,
      "step": 50
    },
    {
      "epoch": 0.125,
      "grad_norm": 1.7367103099822998,
      "learning_rate": 1.9175000000000002e-05,
      "loss": 0.6664,
      "step": 100
    },
    {
      "epoch": 0.1875,
      "grad_norm": 1.3775837421417236,
      "learning_rate": 1.8758333333333333e-05,
      "loss": 0.6336,
      "step": 150
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.45391845703125,
      "learning_rate": 1.8341666666666668e-05,
      "loss": 0.5933,
      "step": 200
    },
    {
      "epoch": 0.3125,
      "grad_norm": 0.8771510124206543,
      "learning_rate": 1.7925000000000002e-05,
      "loss": 0.531,
      "step": 250
    },
    {
      "epoch": 0.375,
      "grad_norm": 1.0410765409469604,
      "learning_rate": 1.7508333333333333e-05,
      "loss": 0.4465,
      "step": 300
    },
    {
      "epoch": 0.4375,
      "grad_norm": 1.1179054975509644,
      "learning_rate": 1.7091666666666668e-05,
      "loss": 0.3365,
      "step": 350
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.3045985698699951,
      "learning_rate": 1.6675000000000002e-05,
      "loss": 0.206,
      "step": 400
    },
    {
      "epoch": 0.5625,
      "grad_norm": 0.30203738808631897,
      "learning_rate": 1.6258333333333333e-05,
      "loss": 0.1064,
      "step": 450
    },
    {
      "epoch": 0.625,
      "grad_norm": 0.7396270036697388,
      "learning_rate": 1.5841666666666668e-05,
      "loss": 0.0586,
      "step": 500
    },
    {
      "epoch": 0.6875,
      "grad_norm": 0.3769104778766632,
      "learning_rate": 1.5425000000000002e-05,
      "loss": 0.0346,
      "step": 550
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.3174094557762146,
      "learning_rate": 1.5008333333333333e-05,
      "loss": 0.0261,
      "step": 600
    },
    {
      "epoch": 0.8125,
      "grad_norm": 0.4213497042655945,
      "learning_rate": 1.4591666666666668e-05,
      "loss": 0.0179,
      "step": 650
    },
    {
      "epoch": 0.875,
      "grad_norm": 0.187461256980896,
      "learning_rate": 1.4175e-05,
      "loss": 0.0157,
      "step": 700
    },
    {
      "epoch": 0.9375,
      "grad_norm": 0.09323673695325851,
      "learning_rate": 1.3758333333333333e-05,
      "loss": 0.0111,
      "step": 750
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.09274282306432724,
      "learning_rate": 1.3341666666666668e-05,
      "loss": 0.0082,
      "step": 800
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 1.0,
      "eval_loss": 0.0021284655667841434,
      "eval_runtime": 2.7916,
      "eval_samples_per_second": 573.147,
      "eval_steps_per_second": 71.643,
      "step": 800
    }
  ],
  "logging_steps": 50,
  "max_steps": 2400,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 212668838707200.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
