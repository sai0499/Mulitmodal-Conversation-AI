{
  "best_metric": 1.0,
  "best_model_checkpoint": "./intent_model_lora\\checkpoint-3200",
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 16000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03125,
      "grad_norm": 2.6466612815856934,
      "learning_rate": 1.99375e-05,
      "loss": 1.3851,
      "step": 50
    },
    {
      "epoch": 0.0625,
      "grad_norm": 4.348769664764404,
      "learning_rate": 1.9875000000000002e-05,
      "loss": 1.3692,
      "step": 100
    },
    {
      "epoch": 0.09375,
      "grad_norm": 4.000590801239014,
      "learning_rate": 1.98125e-05,
      "loss": 1.3503,
      "step": 150
    },
    {
      "epoch": 0.125,
      "grad_norm": 3.3885645866394043,
      "learning_rate": 1.9750000000000002e-05,
      "loss": 1.3131,
      "step": 200
    },
    {
      "epoch": 0.15625,
      "grad_norm": 1.8563917875289917,
      "learning_rate": 1.96875e-05,
      "loss": 1.2492,
      "step": 250
    },
    {
      "epoch": 0.1875,
      "grad_norm": 2.647984504699707,
      "learning_rate": 1.9625e-05,
      "loss": 1.1659,
      "step": 300
    },
    {
      "epoch": 0.21875,
      "grad_norm": 3.7272496223449707,
      "learning_rate": 1.95625e-05,
      "loss": 0.9876,
      "step": 350
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.8592309951782227,
      "learning_rate": 1.95e-05,
      "loss": 0.7398,
      "step": 400
    },
    {
      "epoch": 0.28125,
      "grad_norm": 1.8497697114944458,
      "learning_rate": 1.94375e-05,
      "loss": 0.5035,
      "step": 450
    },
    {
      "epoch": 0.3125,
      "grad_norm": 1.0768684148788452,
      "learning_rate": 1.9375e-05,
      "loss": 0.34,
      "step": 500
    },
    {
      "epoch": 0.34375,
      "grad_norm": 2.4202587604522705,
      "learning_rate": 1.9312500000000002e-05,
      "loss": 0.2247,
      "step": 550
    },
    {
      "epoch": 0.375,
      "grad_norm": 2.209779977798462,
      "learning_rate": 1.925e-05,
      "loss": 0.1458,
      "step": 600
    },
    {
      "epoch": 0.40625,
      "grad_norm": 0.3214394450187683,
      "learning_rate": 1.9187500000000002e-05,
      "loss": 0.0891,
      "step": 650
    },
    {
      "epoch": 0.4375,
      "grad_norm": 0.7232575416564941,
      "learning_rate": 1.9125000000000004e-05,
      "loss": 0.082,
      "step": 700
    },
    {
      "epoch": 0.46875,
      "grad_norm": 0.49410200119018555,
      "learning_rate": 1.9062500000000003e-05,
      "loss": 0.0521,
      "step": 750
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.15571095049381256,
      "learning_rate": 1.9e-05,
      "loss": 0.0399,
      "step": 800
    },
    {
      "epoch": 0.53125,
      "grad_norm": 0.46335381269454956,
      "learning_rate": 1.8937500000000003e-05,
      "loss": 0.0331,
      "step": 850
    },
    {
      "epoch": 0.5625,
      "grad_norm": 0.6533365249633789,
      "learning_rate": 1.8875e-05,
      "loss": 0.0337,
      "step": 900
    },
    {
      "epoch": 0.59375,
      "grad_norm": 0.30037760734558105,
      "learning_rate": 1.8812500000000003e-05,
      "loss": 0.0329,
      "step": 950
    },
    {
      "epoch": 0.625,
      "grad_norm": 0.12092756479978561,
      "learning_rate": 1.8750000000000002e-05,
      "loss": 0.0258,
      "step": 1000
    },
    {
      "epoch": 0.65625,
      "grad_norm": 0.13727404177188873,
      "learning_rate": 1.86875e-05,
      "loss": 0.023,
      "step": 1050
    },
    {
      "epoch": 0.6875,
      "grad_norm": 1.4153751134872437,
      "learning_rate": 1.8625000000000002e-05,
      "loss": 0.0167,
      "step": 1100
    },
    {
      "epoch": 0.71875,
      "grad_norm": 0.23862728476524353,
      "learning_rate": 1.85625e-05,
      "loss": 0.0349,
      "step": 1150
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.0663246363401413,
      "learning_rate": 1.8500000000000002e-05,
      "loss": 0.0258,
      "step": 1200
    },
    {
      "epoch": 0.78125,
      "grad_norm": 0.15144231915473938,
      "learning_rate": 1.84375e-05,
      "loss": 0.0136,
      "step": 1250
    },
    {
      "epoch": 0.8125,
      "grad_norm": 0.11287777125835419,
      "learning_rate": 1.8375e-05,
      "loss": 0.0091,
      "step": 1300
    },
    {
      "epoch": 0.84375,
      "grad_norm": 0.1982538104057312,
      "learning_rate": 1.83125e-05,
      "loss": 0.014,
      "step": 1350
    },
    {
      "epoch": 0.875,
      "grad_norm": 0.03663968667387962,
      "learning_rate": 1.825e-05,
      "loss": 0.0167,
      "step": 1400
    },
    {
      "epoch": 0.90625,
      "grad_norm": 0.05048050731420517,
      "learning_rate": 1.81875e-05,
      "loss": 0.0137,
      "step": 1450
    },
    {
      "epoch": 0.9375,
      "grad_norm": 0.11479121446609497,
      "learning_rate": 1.8125e-05,
      "loss": 0.0088,
      "step": 1500
    },
    {
      "epoch": 0.96875,
      "grad_norm": 0.03425576537847519,
      "learning_rate": 1.8062500000000002e-05,
      "loss": 0.0095,
      "step": 1550
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.25099867582321167,
      "learning_rate": 1.8e-05,
      "loss": 0.0066,
      "step": 1600
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9990625,
      "eval_loss": 0.003340532537549734,
      "eval_runtime": 5.4588,
      "eval_samples_per_second": 586.212,
      "eval_steps_per_second": 73.277,
      "step": 1600
    },
    {
      "epoch": 1.03125,
      "grad_norm": 0.04053747281432152,
      "learning_rate": 1.7937500000000002e-05,
      "loss": 0.0066,
      "step": 1650
    },
    {
      "epoch": 1.0625,
      "grad_norm": 0.04011974856257439,
      "learning_rate": 1.7875e-05,
      "loss": 0.0249,
      "step": 1700
    },
    {
      "epoch": 1.09375,
      "grad_norm": 0.48038145899772644,
      "learning_rate": 1.7812500000000003e-05,
      "loss": 0.0056,
      "step": 1750
    },
    {
      "epoch": 1.125,
      "grad_norm": 0.021924324333667755,
      "learning_rate": 1.775e-05,
      "loss": 0.0091,
      "step": 1800
    },
    {
      "epoch": 1.15625,
      "grad_norm": 0.027159998193383217,
      "learning_rate": 1.7687500000000003e-05,
      "loss": 0.0032,
      "step": 1850
    },
    {
      "epoch": 1.1875,
      "grad_norm": 0.1464432030916214,
      "learning_rate": 1.7625e-05,
      "loss": 0.0049,
      "step": 1900
    },
    {
      "epoch": 1.21875,
      "grad_norm": 1.267929196357727,
      "learning_rate": 1.7562500000000003e-05,
      "loss": 0.0164,
      "step": 1950
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.030387619510293007,
      "learning_rate": 1.7500000000000002e-05,
      "loss": 0.0052,
      "step": 2000
    },
    {
      "epoch": 1.28125,
      "grad_norm": 0.029733087867498398,
      "learning_rate": 1.74375e-05,
      "loss": 0.0042,
      "step": 2050
    },
    {
      "epoch": 1.3125,
      "grad_norm": 0.0631096214056015,
      "learning_rate": 1.7375000000000002e-05,
      "loss": 0.0034,
      "step": 2100
    },
    {
      "epoch": 1.34375,
      "grad_norm": 0.021099887788295746,
      "learning_rate": 1.73125e-05,
      "loss": 0.0036,
      "step": 2150
    },
    {
      "epoch": 1.375,
      "grad_norm": 0.010204446502029896,
      "learning_rate": 1.7250000000000003e-05,
      "loss": 0.0034,
      "step": 2200
    },
    {
      "epoch": 1.40625,
      "grad_norm": 0.031751520931720734,
      "learning_rate": 1.71875e-05,
      "loss": 0.0039,
      "step": 2250
    },
    {
      "epoch": 1.4375,
      "grad_norm": 0.09187236428260803,
      "learning_rate": 1.7125e-05,
      "loss": 0.0046,
      "step": 2300
    },
    {
      "epoch": 1.46875,
      "grad_norm": 0.10151553153991699,
      "learning_rate": 1.70625e-05,
      "loss": 0.0042,
      "step": 2350
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.024418989196419716,
      "learning_rate": 1.7e-05,
      "loss": 0.0025,
      "step": 2400
    },
    {
      "epoch": 1.53125,
      "grad_norm": 0.037188295274972916,
      "learning_rate": 1.6937500000000002e-05,
      "loss": 0.0024,
      "step": 2450
    },
    {
      "epoch": 1.5625,
      "grad_norm": 0.04482686147093773,
      "learning_rate": 1.6875e-05,
      "loss": 0.0145,
      "step": 2500
    },
    {
      "epoch": 1.59375,
      "grad_norm": 0.018953129649162292,
      "learning_rate": 1.6812500000000002e-05,
      "loss": 0.0048,
      "step": 2550
    },
    {
      "epoch": 1.625,
      "grad_norm": 0.014423120766878128,
      "learning_rate": 1.675e-05,
      "loss": 0.0039,
      "step": 2600
    },
    {
      "epoch": 1.65625,
      "grad_norm": 0.15246464312076569,
      "learning_rate": 1.6687500000000002e-05,
      "loss": 0.0084,
      "step": 2650
    },
    {
      "epoch": 1.6875,
      "grad_norm": 0.031640056520700455,
      "learning_rate": 1.6625e-05,
      "loss": 0.003,
      "step": 2700
    },
    {
      "epoch": 1.71875,
      "grad_norm": 0.011555535718798637,
      "learning_rate": 1.6562500000000003e-05,
      "loss": 0.0034,
      "step": 2750
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.024385793134570122,
      "learning_rate": 1.65e-05,
      "loss": 0.0019,
      "step": 2800
    },
    {
      "epoch": 1.78125,
      "grad_norm": 0.026306649670004845,
      "learning_rate": 1.6437500000000003e-05,
      "loss": 0.0095,
      "step": 2850
    },
    {
      "epoch": 1.8125,
      "grad_norm": 0.029986819252371788,
      "learning_rate": 1.6375e-05,
      "loss": 0.0026,
      "step": 2900
    },
    {
      "epoch": 1.84375,
      "grad_norm": 0.033798281103372574,
      "learning_rate": 1.6312500000000003e-05,
      "loss": 0.0023,
      "step": 2950
    },
    {
      "epoch": 1.875,
      "grad_norm": 0.01371206995099783,
      "learning_rate": 1.6250000000000002e-05,
      "loss": 0.0064,
      "step": 3000
    },
    {
      "epoch": 1.90625,
      "grad_norm": 0.022420046851038933,
      "learning_rate": 1.61875e-05,
      "loss": 0.0012,
      "step": 3050
    },
    {
      "epoch": 1.9375,
      "grad_norm": 0.03195963799953461,
      "learning_rate": 1.6125000000000002e-05,
      "loss": 0.0061,
      "step": 3100
    },
    {
      "epoch": 1.96875,
      "grad_norm": 0.015943335369229317,
      "learning_rate": 1.60625e-05,
      "loss": 0.0022,
      "step": 3150
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.007998022250831127,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.0026,
      "step": 3200
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 1.0,
      "eval_loss": 0.0008789908606559038,
      "eval_runtime": 5.464,
      "eval_samples_per_second": 585.648,
      "eval_steps_per_second": 73.206,
      "step": 3200
    },
    {
      "epoch": 2.03125,
      "grad_norm": 0.026722976937890053,
      "learning_rate": 1.59375e-05,
      "loss": 0.002,
      "step": 3250
    },
    {
      "epoch": 2.0625,
      "grad_norm": 0.008407368324697018,
      "learning_rate": 1.5875e-05,
      "loss": 0.0116,
      "step": 3300
    },
    {
      "epoch": 2.09375,
      "grad_norm": 0.007211667485535145,
      "learning_rate": 1.58125e-05,
      "loss": 0.0016,
      "step": 3350
    },
    {
      "epoch": 2.125,
      "grad_norm": 0.0184563547372818,
      "learning_rate": 1.575e-05,
      "loss": 0.0031,
      "step": 3400
    },
    {
      "epoch": 2.15625,
      "grad_norm": 0.16780367493629456,
      "learning_rate": 1.5687500000000002e-05,
      "loss": 0.001,
      "step": 3450
    },
    {
      "epoch": 2.1875,
      "grad_norm": 0.2269209921360016,
      "learning_rate": 1.5625e-05,
      "loss": 0.002,
      "step": 3500
    },
    {
      "epoch": 2.21875,
      "grad_norm": 0.013709668070077896,
      "learning_rate": 1.55625e-05,
      "loss": 0.0014,
      "step": 3550
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.019591275602579117,
      "learning_rate": 1.55e-05,
      "loss": 0.001,
      "step": 3600
    },
    {
      "epoch": 2.28125,
      "grad_norm": 0.013261612504720688,
      "learning_rate": 1.54375e-05,
      "loss": 0.0057,
      "step": 3650
    },
    {
      "epoch": 2.3125,
      "grad_norm": 0.0012143084313720465,
      "learning_rate": 1.5375e-05,
      "loss": 0.0014,
      "step": 3700
    },
    {
      "epoch": 2.34375,
      "grad_norm": 0.011739188805222511,
      "learning_rate": 1.5312500000000003e-05,
      "loss": 0.003,
      "step": 3750
    },
    {
      "epoch": 2.375,
      "grad_norm": 0.01271950826048851,
      "learning_rate": 1.525e-05,
      "loss": 0.0023,
      "step": 3800
    },
    {
      "epoch": 2.40625,
      "grad_norm": 0.011181546375155449,
      "learning_rate": 1.5187500000000002e-05,
      "loss": 0.0017,
      "step": 3850
    },
    {
      "epoch": 2.4375,
      "grad_norm": 0.003435454796999693,
      "learning_rate": 1.5125e-05,
      "loss": 0.0016,
      "step": 3900
    },
    {
      "epoch": 2.46875,
      "grad_norm": 0.01308672409504652,
      "learning_rate": 1.5062500000000002e-05,
      "loss": 0.0061,
      "step": 3950
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.005640703719109297,
      "learning_rate": 1.5000000000000002e-05,
      "loss": 0.0033,
      "step": 4000
    },
    {
      "epoch": 2.53125,
      "grad_norm": 0.009474231861531734,
      "learning_rate": 1.49375e-05,
      "loss": 0.0007,
      "step": 4050
    },
    {
      "epoch": 2.5625,
      "grad_norm": 0.11847975850105286,
      "learning_rate": 1.4875000000000002e-05,
      "loss": 0.0019,
      "step": 4100
    },
    {
      "epoch": 2.59375,
      "grad_norm": 0.02606200985610485,
      "learning_rate": 1.4812500000000001e-05,
      "loss": 0.0006,
      "step": 4150
    },
    {
      "epoch": 2.625,
      "grad_norm": 0.010061081498861313,
      "learning_rate": 1.4750000000000003e-05,
      "loss": 0.0014,
      "step": 4200
    },
    {
      "epoch": 2.65625,
      "grad_norm": 0.07604826241731644,
      "learning_rate": 1.4687500000000001e-05,
      "loss": 0.0039,
      "step": 4250
    },
    {
      "epoch": 2.6875,
      "grad_norm": 0.00302249938249588,
      "learning_rate": 1.4625e-05,
      "loss": 0.0006,
      "step": 4300
    },
    {
      "epoch": 2.71875,
      "grad_norm": 0.0034816518891602755,
      "learning_rate": 1.4562500000000002e-05,
      "loss": 0.0007,
      "step": 4350
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.003505781525745988,
      "learning_rate": 1.45e-05,
      "loss": 0.007,
      "step": 4400
    },
    {
      "epoch": 2.78125,
      "grad_norm": 0.007873326539993286,
      "learning_rate": 1.4437500000000002e-05,
      "loss": 0.0021,
      "step": 4450
    },
    {
      "epoch": 2.8125,
      "grad_norm": 0.00881273951381445,
      "learning_rate": 1.4375e-05,
      "loss": 0.0093,
      "step": 4500
    },
    {
      "epoch": 2.84375,
      "grad_norm": 0.00661170668900013,
      "learning_rate": 1.43125e-05,
      "loss": 0.0005,
      "step": 4550
    },
    {
      "epoch": 2.875,
      "grad_norm": 0.017942270264029503,
      "learning_rate": 1.425e-05,
      "loss": 0.0016,
      "step": 4600
    },
    {
      "epoch": 2.90625,
      "grad_norm": 0.00782901793718338,
      "learning_rate": 1.4187500000000001e-05,
      "loss": 0.0006,
      "step": 4650
    },
    {
      "epoch": 2.9375,
      "grad_norm": 0.007080619223415852,
      "learning_rate": 1.4125000000000003e-05,
      "loss": 0.0023,
      "step": 4700
    },
    {
      "epoch": 2.96875,
      "grad_norm": 0.0038515476044267416,
      "learning_rate": 1.4062500000000001e-05,
      "loss": 0.0018,
      "step": 4750
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.09286580979824066,
      "learning_rate": 1.4e-05,
      "loss": 0.0005,
      "step": 4800
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 1.0,
      "eval_loss": 0.0003162575012538582,
      "eval_runtime": 5.4538,
      "eval_samples_per_second": 586.743,
      "eval_steps_per_second": 73.343,
      "step": 4800
    },
    {
      "epoch": 3.03125,
      "grad_norm": 0.06785797327756882,
      "learning_rate": 1.3937500000000002e-05,
      "loss": 0.0039,
      "step": 4850
    },
    {
      "epoch": 3.0625,
      "grad_norm": 0.0012202404905110598,
      "learning_rate": 1.3875e-05,
      "loss": 0.0012,
      "step": 4900
    },
    {
      "epoch": 3.09375,
      "grad_norm": 0.004109743516892195,
      "learning_rate": 1.3812500000000002e-05,
      "loss": 0.0005,
      "step": 4950
    },
    {
      "epoch": 3.125,
      "grad_norm": 0.009851624257862568,
      "learning_rate": 1.375e-05,
      "loss": 0.002,
      "step": 5000
    },
    {
      "epoch": 3.15625,
      "grad_norm": 0.06564276665449142,
      "learning_rate": 1.36875e-05,
      "loss": 0.0007,
      "step": 5050
    },
    {
      "epoch": 3.1875,
      "grad_norm": 0.0002746785758063197,
      "learning_rate": 1.3625e-05,
      "loss": 0.0028,
      "step": 5100
    },
    {
      "epoch": 3.21875,
      "grad_norm": 0.022801894694566727,
      "learning_rate": 1.3562500000000001e-05,
      "loss": 0.0008,
      "step": 5150
    },
    {
      "epoch": 3.25,
      "grad_norm": 0.006361563224345446,
      "learning_rate": 1.3500000000000001e-05,
      "loss": 0.0006,
      "step": 5200
    },
    {
      "epoch": 3.28125,
      "grad_norm": 0.001157408463768661,
      "learning_rate": 1.3437500000000001e-05,
      "loss": 0.0006,
      "step": 5250
    },
    {
      "epoch": 3.3125,
      "grad_norm": 0.011191923171281815,
      "learning_rate": 1.3375e-05,
      "loss": 0.0022,
      "step": 5300
    },
    {
      "epoch": 3.34375,
      "grad_norm": 0.006268058903515339,
      "learning_rate": 1.3312500000000002e-05,
      "loss": 0.0005,
      "step": 5350
    },
    {
      "epoch": 3.375,
      "grad_norm": 0.022451089695096016,
      "learning_rate": 1.325e-05,
      "loss": 0.0013,
      "step": 5400
    },
    {
      "epoch": 3.40625,
      "grad_norm": 0.0014007698046043515,
      "learning_rate": 1.3187500000000002e-05,
      "loss": 0.0013,
      "step": 5450
    },
    {
      "epoch": 3.4375,
      "grad_norm": 0.004094703588634729,
      "learning_rate": 1.3125e-05,
      "loss": 0.0046,
      "step": 5500
    },
    {
      "epoch": 3.46875,
      "grad_norm": 0.0019709954503923655,
      "learning_rate": 1.30625e-05,
      "loss": 0.0099,
      "step": 5550
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.0016467616660520434,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 0.0005,
      "step": 5600
    },
    {
      "epoch": 3.53125,
      "grad_norm": 0.002592976437881589,
      "learning_rate": 1.2937500000000001e-05,
      "loss": 0.0005,
      "step": 5650
    },
    {
      "epoch": 3.5625,
      "grad_norm": 0.0033629387617111206,
      "learning_rate": 1.2875000000000001e-05,
      "loss": 0.0004,
      "step": 5700
    },
    {
      "epoch": 3.59375,
      "grad_norm": 0.0023072310723364353,
      "learning_rate": 1.2812500000000001e-05,
      "loss": 0.0014,
      "step": 5750
    },
    {
      "epoch": 3.625,
      "grad_norm": 0.014175273478031158,
      "learning_rate": 1.275e-05,
      "loss": 0.0004,
      "step": 5800
    },
    {
      "epoch": 3.65625,
      "grad_norm": 0.003277495037764311,
      "learning_rate": 1.2687500000000002e-05,
      "loss": 0.0054,
      "step": 5850
    },
    {
      "epoch": 3.6875,
      "grad_norm": 0.0009728128206916153,
      "learning_rate": 1.2625e-05,
      "loss": 0.0004,
      "step": 5900
    },
    {
      "epoch": 3.71875,
      "grad_norm": 0.008599997498095036,
      "learning_rate": 1.2562500000000002e-05,
      "loss": 0.0011,
      "step": 5950
    },
    {
      "epoch": 3.75,
      "grad_norm": 0.0022270448971539736,
      "learning_rate": 1.25e-05,
      "loss": 0.0004,
      "step": 6000
    },
    {
      "epoch": 3.78125,
      "grad_norm": 0.001285531441681087,
      "learning_rate": 1.24375e-05,
      "loss": 0.0003,
      "step": 6050
    },
    {
      "epoch": 3.8125,
      "grad_norm": 0.016372036188840866,
      "learning_rate": 1.2375000000000001e-05,
      "loss": 0.0005,
      "step": 6100
    },
    {
      "epoch": 3.84375,
      "grad_norm": 0.0029464575927704573,
      "learning_rate": 1.2312500000000001e-05,
      "loss": 0.0023,
      "step": 6150
    },
    {
      "epoch": 3.875,
      "grad_norm": 0.012788927182555199,
      "learning_rate": 1.2250000000000001e-05,
      "loss": 0.0006,
      "step": 6200
    },
    {
      "epoch": 3.90625,
      "grad_norm": 0.0008264958742074668,
      "learning_rate": 1.2187500000000001e-05,
      "loss": 0.0012,
      "step": 6250
    },
    {
      "epoch": 3.9375,
      "grad_norm": 0.0014306068187579513,
      "learning_rate": 1.2125e-05,
      "loss": 0.0018,
      "step": 6300
    },
    {
      "epoch": 3.96875,
      "grad_norm": 0.010961385443806648,
      "learning_rate": 1.2062500000000002e-05,
      "loss": 0.0006,
      "step": 6350
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.0012445971369743347,
      "learning_rate": 1.2e-05,
      "loss": 0.0058,
      "step": 6400
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 1.0,
      "eval_loss": 0.00010705552995204926,
      "eval_runtime": 5.8024,
      "eval_samples_per_second": 551.499,
      "eval_steps_per_second": 68.937,
      "step": 6400
    },
    {
      "epoch": 4.03125,
      "grad_norm": 0.00786131713539362,
      "learning_rate": 1.1937500000000002e-05,
      "loss": 0.0003,
      "step": 6450
    },
    {
      "epoch": 4.0625,
      "grad_norm": 0.0016520025674253702,
      "learning_rate": 1.1875e-05,
      "loss": 0.0017,
      "step": 6500
    },
    {
      "epoch": 4.09375,
      "grad_norm": 0.0046677859500050545,
      "learning_rate": 1.18125e-05,
      "loss": 0.0007,
      "step": 6550
    },
    {
      "epoch": 4.125,
      "grad_norm": 0.6276225447654724,
      "learning_rate": 1.1750000000000001e-05,
      "loss": 0.0065,
      "step": 6600
    },
    {
      "epoch": 4.15625,
      "grad_norm": 0.003954241052269936,
      "learning_rate": 1.1687500000000001e-05,
      "loss": 0.0015,
      "step": 6650
    },
    {
      "epoch": 4.1875,
      "grad_norm": 0.0010746144689619541,
      "learning_rate": 1.1625000000000001e-05,
      "loss": 0.0004,
      "step": 6700
    },
    {
      "epoch": 4.21875,
      "grad_norm": 0.00040235419874079525,
      "learning_rate": 1.1562500000000002e-05,
      "loss": 0.0035,
      "step": 6750
    },
    {
      "epoch": 4.25,
      "grad_norm": 0.0012946927454322577,
      "learning_rate": 1.15e-05,
      "loss": 0.0023,
      "step": 6800
    },
    {
      "epoch": 4.28125,
      "grad_norm": 0.001170631148852408,
      "learning_rate": 1.1437500000000002e-05,
      "loss": 0.0012,
      "step": 6850
    },
    {
      "epoch": 4.3125,
      "grad_norm": 0.049330540001392365,
      "learning_rate": 1.1375e-05,
      "loss": 0.0007,
      "step": 6900
    },
    {
      "epoch": 4.34375,
      "grad_norm": 0.00025743633159436285,
      "learning_rate": 1.1312500000000002e-05,
      "loss": 0.0009,
      "step": 6950
    },
    {
      "epoch": 4.375,
      "grad_norm": 0.00025892496341839433,
      "learning_rate": 1.125e-05,
      "loss": 0.0003,
      "step": 7000
    },
    {
      "epoch": 4.40625,
      "grad_norm": 0.0021222715731710196,
      "learning_rate": 1.11875e-05,
      "loss": 0.0002,
      "step": 7050
    },
    {
      "epoch": 4.4375,
      "grad_norm": 0.017376072704792023,
      "learning_rate": 1.1125000000000001e-05,
      "loss": 0.001,
      "step": 7100
    },
    {
      "epoch": 4.46875,
      "grad_norm": 0.0027600927278399467,
      "learning_rate": 1.1062500000000001e-05,
      "loss": 0.0014,
      "step": 7150
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.0045785242691636086,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 0.002,
      "step": 7200
    },
    {
      "epoch": 4.53125,
      "grad_norm": 0.0005632049287669361,
      "learning_rate": 1.0937500000000002e-05,
      "loss": 0.0005,
      "step": 7250
    },
    {
      "epoch": 4.5625,
      "grad_norm": 0.0022687700111418962,
      "learning_rate": 1.0875e-05,
      "loss": 0.0002,
      "step": 7300
    },
    {
      "epoch": 4.59375,
      "grad_norm": 0.0003329711908008903,
      "learning_rate": 1.0812500000000002e-05,
      "loss": 0.0004,
      "step": 7350
    },
    {
      "epoch": 4.625,
      "grad_norm": 0.00026889133732765913,
      "learning_rate": 1.075e-05,
      "loss": 0.0006,
      "step": 7400
    },
    {
      "epoch": 4.65625,
      "grad_norm": 0.0013383211335167289,
      "learning_rate": 1.0687500000000002e-05,
      "loss": 0.0002,
      "step": 7450
    },
    {
      "epoch": 4.6875,
      "grad_norm": 0.19150954484939575,
      "learning_rate": 1.0625e-05,
      "loss": 0.0005,
      "step": 7500
    },
    {
      "epoch": 4.71875,
      "grad_norm": 0.0017467217985540628,
      "learning_rate": 1.05625e-05,
      "loss": 0.0031,
      "step": 7550
    },
    {
      "epoch": 4.75,
      "grad_norm": 0.0022405367344617844,
      "learning_rate": 1.0500000000000001e-05,
      "loss": 0.0015,
      "step": 7600
    },
    {
      "epoch": 4.78125,
      "grad_norm": 0.005105934571474791,
      "learning_rate": 1.04375e-05,
      "loss": 0.0005,
      "step": 7650
    },
    {
      "epoch": 4.8125,
      "grad_norm": 0.00043911527609452605,
      "learning_rate": 1.0375000000000001e-05,
      "loss": 0.0003,
      "step": 7700
    },
    {
      "epoch": 4.84375,
      "grad_norm": 0.045175544917583466,
      "learning_rate": 1.0312500000000002e-05,
      "loss": 0.0003,
      "step": 7750
    },
    {
      "epoch": 4.875,
      "grad_norm": 0.0010091194417327642,
      "learning_rate": 1.025e-05,
      "loss": 0.0003,
      "step": 7800
    },
    {
      "epoch": 4.90625,
      "grad_norm": 0.046502482146024704,
      "learning_rate": 1.0187500000000002e-05,
      "loss": 0.0003,
      "step": 7850
    },
    {
      "epoch": 4.9375,
      "grad_norm": 0.003923974931240082,
      "learning_rate": 1.0125e-05,
      "loss": 0.0002,
      "step": 7900
    },
    {
      "epoch": 4.96875,
      "grad_norm": 0.0025420079473406076,
      "learning_rate": 1.0062500000000002e-05,
      "loss": 0.0004,
      "step": 7950
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.0314595028758049,
      "learning_rate": 1e-05,
      "loss": 0.0003,
      "step": 8000
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 1.0,
      "eval_loss": 4.2780255171237513e-05,
      "eval_runtime": 5.5455,
      "eval_samples_per_second": 577.042,
      "eval_steps_per_second": 72.13,
      "step": 8000
    },
    {
      "epoch": 5.03125,
      "grad_norm": 0.0003681258822325617,
      "learning_rate": 9.937500000000001e-06,
      "loss": 0.001,
      "step": 8050
    },
    {
      "epoch": 5.0625,
      "grad_norm": 0.00315878982655704,
      "learning_rate": 9.875000000000001e-06,
      "loss": 0.0004,
      "step": 8100
    },
    {
      "epoch": 5.09375,
      "grad_norm": 0.0002929744077846408,
      "learning_rate": 9.8125e-06,
      "loss": 0.0003,
      "step": 8150
    },
    {
      "epoch": 5.125,
      "grad_norm": 0.004295113496482372,
      "learning_rate": 9.75e-06,
      "loss": 0.0004,
      "step": 8200
    },
    {
      "epoch": 5.15625,
      "grad_norm": 0.00018920488946605474,
      "learning_rate": 9.6875e-06,
      "loss": 0.0003,
      "step": 8250
    },
    {
      "epoch": 5.1875,
      "grad_norm": 0.0001487977133365348,
      "learning_rate": 9.625e-06,
      "loss": 0.0003,
      "step": 8300
    },
    {
      "epoch": 5.21875,
      "grad_norm": 0.0009254112374037504,
      "learning_rate": 9.562500000000002e-06,
      "loss": 0.0002,
      "step": 8350
    },
    {
      "epoch": 5.25,
      "grad_norm": 0.010197089053690434,
      "learning_rate": 9.5e-06,
      "loss": 0.0007,
      "step": 8400
    },
    {
      "epoch": 5.28125,
      "grad_norm": 0.0007126844138838351,
      "learning_rate": 9.4375e-06,
      "loss": 0.0002,
      "step": 8450
    },
    {
      "epoch": 5.3125,
      "grad_norm": 0.0033848974853754044,
      "learning_rate": 9.375000000000001e-06,
      "loss": 0.0002,
      "step": 8500
    },
    {
      "epoch": 5.34375,
      "grad_norm": 0.00046862353337928653,
      "learning_rate": 9.312500000000001e-06,
      "loss": 0.0002,
      "step": 8550
    },
    {
      "epoch": 5.375,
      "grad_norm": 0.0007723567541688681,
      "learning_rate": 9.250000000000001e-06,
      "loss": 0.0005,
      "step": 8600
    },
    {
      "epoch": 5.40625,
      "grad_norm": 0.003570506814867258,
      "learning_rate": 9.1875e-06,
      "loss": 0.0002,
      "step": 8650
    },
    {
      "epoch": 5.4375,
      "grad_norm": 0.0010598489316180348,
      "learning_rate": 9.125e-06,
      "loss": 0.0003,
      "step": 8700
    },
    {
      "epoch": 5.46875,
      "grad_norm": 9.777172090252861e-05,
      "learning_rate": 9.0625e-06,
      "loss": 0.0002,
      "step": 8750
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.0031915386207401752,
      "learning_rate": 9e-06,
      "loss": 0.0012,
      "step": 8800
    },
    {
      "epoch": 5.53125,
      "grad_norm": 0.006488240323960781,
      "learning_rate": 8.9375e-06,
      "loss": 0.0002,
      "step": 8850
    },
    {
      "epoch": 5.5625,
      "grad_norm": 0.0027759161312133074,
      "learning_rate": 8.875e-06,
      "loss": 0.0003,
      "step": 8900
    },
    {
      "epoch": 5.59375,
      "grad_norm": 0.0006310113240033388,
      "learning_rate": 8.8125e-06,
      "loss": 0.0002,
      "step": 8950
    },
    {
      "epoch": 5.625,
      "grad_norm": 0.018362982198596,
      "learning_rate": 8.750000000000001e-06,
      "loss": 0.0001,
      "step": 9000
    },
    {
      "epoch": 5.65625,
      "grad_norm": 0.0008570930222049356,
      "learning_rate": 8.687500000000001e-06,
      "loss": 0.0014,
      "step": 9050
    },
    {
      "epoch": 5.6875,
      "grad_norm": 0.000305370194837451,
      "learning_rate": 8.625000000000001e-06,
      "loss": 0.0003,
      "step": 9100
    },
    {
      "epoch": 5.71875,
      "grad_norm": 0.001823351252824068,
      "learning_rate": 8.5625e-06,
      "loss": 0.0011,
      "step": 9150
    },
    {
      "epoch": 5.75,
      "grad_norm": 0.003982009831815958,
      "learning_rate": 8.5e-06,
      "loss": 0.0013,
      "step": 9200
    },
    {
      "epoch": 5.78125,
      "grad_norm": 0.030977534130215645,
      "learning_rate": 8.4375e-06,
      "loss": 0.0001,
      "step": 9250
    },
    {
      "epoch": 5.8125,
      "grad_norm": 0.00013717784895561635,
      "learning_rate": 8.375e-06,
      "loss": 0.0004,
      "step": 9300
    },
    {
      "epoch": 5.84375,
      "grad_norm": 0.017804961651563644,
      "learning_rate": 8.3125e-06,
      "loss": 0.0001,
      "step": 9350
    },
    {
      "epoch": 5.875,
      "grad_norm": 0.0009578336030244827,
      "learning_rate": 8.25e-06,
      "loss": 0.003,
      "step": 9400
    },
    {
      "epoch": 5.90625,
      "grad_norm": 0.00023866382252890617,
      "learning_rate": 8.1875e-06,
      "loss": 0.0001,
      "step": 9450
    },
    {
      "epoch": 5.9375,
      "grad_norm": 0.02261820249259472,
      "learning_rate": 8.125000000000001e-06,
      "loss": 0.0002,
      "step": 9500
    },
    {
      "epoch": 5.96875,
      "grad_norm": 0.00046210057917051017,
      "learning_rate": 8.062500000000001e-06,
      "loss": 0.0004,
      "step": 9550
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.0005373504245653749,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.0012,
      "step": 9600
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 1.0,
      "eval_loss": 2.657533150340896e-05,
      "eval_runtime": 5.5071,
      "eval_samples_per_second": 581.063,
      "eval_steps_per_second": 72.633,
      "step": 9600
    },
    {
      "epoch": 6.03125,
      "grad_norm": 0.012783312238752842,
      "learning_rate": 7.9375e-06,
      "loss": 0.0029,
      "step": 9650
    },
    {
      "epoch": 6.0625,
      "grad_norm": 0.0014872438041493297,
      "learning_rate": 7.875e-06,
      "loss": 0.0001,
      "step": 9700
    },
    {
      "epoch": 6.09375,
      "grad_norm": 0.00012648248230107129,
      "learning_rate": 7.8125e-06,
      "loss": 0.0002,
      "step": 9750
    },
    {
      "epoch": 6.125,
      "grad_norm": 0.0005302679492160678,
      "learning_rate": 7.75e-06,
      "loss": 0.0001,
      "step": 9800
    },
    {
      "epoch": 6.15625,
      "grad_norm": 0.0007114710751920938,
      "learning_rate": 7.6875e-06,
      "loss": 0.0003,
      "step": 9850
    },
    {
      "epoch": 6.1875,
      "grad_norm": 0.0015835259109735489,
      "learning_rate": 7.625e-06,
      "loss": 0.0009,
      "step": 9900
    },
    {
      "epoch": 6.21875,
      "grad_norm": 0.0003369824553374201,
      "learning_rate": 7.5625e-06,
      "loss": 0.0001,
      "step": 9950
    },
    {
      "epoch": 6.25,
      "grad_norm": 4.301594257354736,
      "learning_rate": 7.500000000000001e-06,
      "loss": 0.0011,
      "step": 10000
    },
    {
      "epoch": 6.28125,
      "grad_norm": 0.0008445209241472185,
      "learning_rate": 7.437500000000001e-06,
      "loss": 0.0002,
      "step": 10050
    },
    {
      "epoch": 6.3125,
      "grad_norm": 0.10585677623748779,
      "learning_rate": 7.375000000000001e-06,
      "loss": 0.002,
      "step": 10100
    },
    {
      "epoch": 6.34375,
      "grad_norm": 0.00024177790328394622,
      "learning_rate": 7.3125e-06,
      "loss": 0.0002,
      "step": 10150
    },
    {
      "epoch": 6.375,
      "grad_norm": 0.0006604758673347533,
      "learning_rate": 7.25e-06,
      "loss": 0.0019,
      "step": 10200
    },
    {
      "epoch": 6.40625,
      "grad_norm": 0.00015705892292317003,
      "learning_rate": 7.1875e-06,
      "loss": 0.0004,
      "step": 10250
    },
    {
      "epoch": 6.4375,
      "grad_norm": 0.00667246850207448,
      "learning_rate": 7.125e-06,
      "loss": 0.0001,
      "step": 10300
    },
    {
      "epoch": 6.46875,
      "grad_norm": 0.0005423291004262865,
      "learning_rate": 7.062500000000001e-06,
      "loss": 0.0001,
      "step": 10350
    },
    {
      "epoch": 6.5,
      "grad_norm": 0.0007637581438757479,
      "learning_rate": 7e-06,
      "loss": 0.0003,
      "step": 10400
    },
    {
      "epoch": 6.53125,
      "grad_norm": 0.00045111190411262214,
      "learning_rate": 6.9375e-06,
      "loss": 0.0001,
      "step": 10450
    },
    {
      "epoch": 6.5625,
      "grad_norm": 0.0006860030698589981,
      "learning_rate": 6.875e-06,
      "loss": 0.0001,
      "step": 10500
    },
    {
      "epoch": 6.59375,
      "grad_norm": 0.0021824813447892666,
      "learning_rate": 6.8125e-06,
      "loss": 0.0004,
      "step": 10550
    },
    {
      "epoch": 6.625,
      "grad_norm": 0.0008713002316653728,
      "learning_rate": 6.750000000000001e-06,
      "loss": 0.0001,
      "step": 10600
    },
    {
      "epoch": 6.65625,
      "grad_norm": 0.00016678374959155917,
      "learning_rate": 6.6875e-06,
      "loss": 0.0001,
      "step": 10650
    },
    {
      "epoch": 6.6875,
      "grad_norm": 0.0001579372037667781,
      "learning_rate": 6.625e-06,
      "loss": 0.0001,
      "step": 10700
    },
    {
      "epoch": 6.71875,
      "grad_norm": 0.03313984349370003,
      "learning_rate": 6.5625e-06,
      "loss": 0.0001,
      "step": 10750
    },
    {
      "epoch": 6.75,
      "grad_norm": 0.0006274470360949636,
      "learning_rate": 6.5000000000000004e-06,
      "loss": 0.0002,
      "step": 10800
    },
    {
      "epoch": 6.78125,
      "grad_norm": 0.0003212725860066712,
      "learning_rate": 6.437500000000001e-06,
      "loss": 0.0008,
      "step": 10850
    },
    {
      "epoch": 6.8125,
      "grad_norm": 0.0003569043183233589,
      "learning_rate": 6.375e-06,
      "loss": 0.0002,
      "step": 10900
    },
    {
      "epoch": 6.84375,
      "grad_norm": 0.11689582467079163,
      "learning_rate": 6.3125e-06,
      "loss": 0.0004,
      "step": 10950
    },
    {
      "epoch": 6.875,
      "grad_norm": 0.0005930186598561704,
      "learning_rate": 6.25e-06,
      "loss": 0.0001,
      "step": 11000
    },
    {
      "epoch": 6.90625,
      "grad_norm": 0.0011774642625823617,
      "learning_rate": 6.1875000000000005e-06,
      "loss": 0.0002,
      "step": 11050
    },
    {
      "epoch": 6.9375,
      "grad_norm": 0.23103423416614532,
      "learning_rate": 6.125000000000001e-06,
      "loss": 0.0004,
      "step": 11100
    },
    {
      "epoch": 6.96875,
      "grad_norm": 0.0010503156809136271,
      "learning_rate": 6.0625e-06,
      "loss": 0.0001,
      "step": 11150
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.04995264485478401,
      "learning_rate": 6e-06,
      "loss": 0.0012,
      "step": 11200
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 1.0,
      "eval_loss": 1.825688377721235e-05,
      "eval_runtime": 5.4669,
      "eval_samples_per_second": 585.344,
      "eval_steps_per_second": 73.168,
      "step": 11200
    },
    {
      "epoch": 7.03125,
      "grad_norm": 0.0001647612516535446,
      "learning_rate": 5.9375e-06,
      "loss": 0.0001,
      "step": 11250
    },
    {
      "epoch": 7.0625,
      "grad_norm": 0.0018197825411334634,
      "learning_rate": 5.8750000000000005e-06,
      "loss": 0.0012,
      "step": 11300
    },
    {
      "epoch": 7.09375,
      "grad_norm": 0.0004689149500336498,
      "learning_rate": 5.812500000000001e-06,
      "loss": 0.0001,
      "step": 11350
    },
    {
      "epoch": 7.125,
      "grad_norm": 0.0028334264643490314,
      "learning_rate": 5.75e-06,
      "loss": 0.0036,
      "step": 11400
    },
    {
      "epoch": 7.15625,
      "grad_norm": 0.0019959115888923407,
      "learning_rate": 5.6875e-06,
      "loss": 0.0005,
      "step": 11450
    },
    {
      "epoch": 7.1875,
      "grad_norm": 0.00037767220055684447,
      "learning_rate": 5.625e-06,
      "loss": 0.0001,
      "step": 11500
    },
    {
      "epoch": 7.21875,
      "grad_norm": 0.0023182379081845284,
      "learning_rate": 5.5625000000000005e-06,
      "loss": 0.0001,
      "step": 11550
    },
    {
      "epoch": 7.25,
      "grad_norm": 0.00011202420137124136,
      "learning_rate": 5.500000000000001e-06,
      "loss": 0.0041,
      "step": 11600
    },
    {
      "epoch": 7.28125,
      "grad_norm": 0.001612933585420251,
      "learning_rate": 5.4375e-06,
      "loss": 0.0002,
      "step": 11650
    },
    {
      "epoch": 7.3125,
      "grad_norm": 0.02927306666970253,
      "learning_rate": 5.375e-06,
      "loss": 0.0006,
      "step": 11700
    },
    {
      "epoch": 7.34375,
      "grad_norm": 0.0015695457113906741,
      "learning_rate": 5.3125e-06,
      "loss": 0.0026,
      "step": 11750
    },
    {
      "epoch": 7.375,
      "grad_norm": 9.734970808494836e-05,
      "learning_rate": 5.2500000000000006e-06,
      "loss": 0.0006,
      "step": 11800
    },
    {
      "epoch": 7.40625,
      "grad_norm": 0.0006732234614901245,
      "learning_rate": 5.187500000000001e-06,
      "loss": 0.0002,
      "step": 11850
    },
    {
      "epoch": 7.4375,
      "grad_norm": 0.00046558910980820656,
      "learning_rate": 5.125e-06,
      "loss": 0.0001,
      "step": 11900
    },
    {
      "epoch": 7.46875,
      "grad_norm": 0.0044081807136535645,
      "learning_rate": 5.0625e-06,
      "loss": 0.0005,
      "step": 11950
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.0023108175955712795,
      "learning_rate": 5e-06,
      "loss": 0.0003,
      "step": 12000
    },
    {
      "epoch": 7.53125,
      "grad_norm": 0.0002183345495723188,
      "learning_rate": 4.937500000000001e-06,
      "loss": 0.0002,
      "step": 12050
    },
    {
      "epoch": 7.5625,
      "grad_norm": 0.00039690715493634343,
      "learning_rate": 4.875e-06,
      "loss": 0.0003,
      "step": 12100
    },
    {
      "epoch": 7.59375,
      "grad_norm": 0.001312078209593892,
      "learning_rate": 4.8125e-06,
      "loss": 0.0001,
      "step": 12150
    },
    {
      "epoch": 7.625,
      "grad_norm": 0.0024029265623539686,
      "learning_rate": 4.75e-06,
      "loss": 0.0008,
      "step": 12200
    },
    {
      "epoch": 7.65625,
      "grad_norm": 0.0007405600044876337,
      "learning_rate": 4.6875000000000004e-06,
      "loss": 0.0001,
      "step": 12250
    },
    {
      "epoch": 7.6875,
      "grad_norm": 0.00918489508330822,
      "learning_rate": 4.625000000000001e-06,
      "loss": 0.0003,
      "step": 12300
    },
    {
      "epoch": 7.71875,
      "grad_norm": 0.00047735244152136147,
      "learning_rate": 4.5625e-06,
      "loss": 0.0001,
      "step": 12350
    },
    {
      "epoch": 7.75,
      "grad_norm": 0.00011765904491767287,
      "learning_rate": 4.5e-06,
      "loss": 0.0,
      "step": 12400
    },
    {
      "epoch": 7.78125,
      "grad_norm": 0.004777359776198864,
      "learning_rate": 4.4375e-06,
      "loss": 0.0001,
      "step": 12450
    },
    {
      "epoch": 7.8125,
      "grad_norm": 0.004243014380335808,
      "learning_rate": 4.3750000000000005e-06,
      "loss": 0.0001,
      "step": 12500
    },
    {
      "epoch": 7.84375,
      "grad_norm": 2.5769299099920318e-05,
      "learning_rate": 4.312500000000001e-06,
      "loss": 0.0001,
      "step": 12550
    },
    {
      "epoch": 7.875,
      "grad_norm": 0.0027493166271597147,
      "learning_rate": 4.25e-06,
      "loss": 0.0001,
      "step": 12600
    },
    {
      "epoch": 7.90625,
      "grad_norm": 0.006216317880898714,
      "learning_rate": 4.1875e-06,
      "loss": 0.0001,
      "step": 12650
    },
    {
      "epoch": 7.9375,
      "grad_norm": 0.016615500673651695,
      "learning_rate": 4.125e-06,
      "loss": 0.0002,
      "step": 12700
    },
    {
      "epoch": 7.96875,
      "grad_norm": 0.0007068751147016883,
      "learning_rate": 4.0625000000000005e-06,
      "loss": 0.0001,
      "step": 12750
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.0019713416695594788,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.0001,
      "step": 12800
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 1.0,
      "eval_loss": 9.48492106545018e-06,
      "eval_runtime": 5.4419,
      "eval_samples_per_second": 588.032,
      "eval_steps_per_second": 73.504,
      "step": 12800
    },
    {
      "epoch": 8.03125,
      "grad_norm": 0.0011470586759969592,
      "learning_rate": 3.9375e-06,
      "loss": 0.0001,
      "step": 12850
    },
    {
      "epoch": 8.0625,
      "grad_norm": 0.00026709178928285837,
      "learning_rate": 3.875e-06,
      "loss": 0.0001,
      "step": 12900
    },
    {
      "epoch": 8.09375,
      "grad_norm": 0.0002746799145825207,
      "learning_rate": 3.8125e-06,
      "loss": 0.0003,
      "step": 12950
    },
    {
      "epoch": 8.125,
      "grad_norm": 0.0010337879648432136,
      "learning_rate": 3.7500000000000005e-06,
      "loss": 0.0001,
      "step": 13000
    },
    {
      "epoch": 8.15625,
      "grad_norm": 0.00435057794675231,
      "learning_rate": 3.6875000000000007e-06,
      "loss": 0.0001,
      "step": 13050
    },
    {
      "epoch": 8.1875,
      "grad_norm": 0.0012692505260929465,
      "learning_rate": 3.625e-06,
      "loss": 0.0006,
      "step": 13100
    },
    {
      "epoch": 8.21875,
      "grad_norm": 5.929678081884049e-05,
      "learning_rate": 3.5625e-06,
      "loss": 0.0006,
      "step": 13150
    },
    {
      "epoch": 8.25,
      "grad_norm": 0.10092348605394363,
      "learning_rate": 3.5e-06,
      "loss": 0.0006,
      "step": 13200
    },
    {
      "epoch": 8.28125,
      "grad_norm": 0.00024359559756703675,
      "learning_rate": 3.4375e-06,
      "loss": 0.0001,
      "step": 13250
    },
    {
      "epoch": 8.3125,
      "grad_norm": 0.0035280215088278055,
      "learning_rate": 3.3750000000000003e-06,
      "loss": 0.0,
      "step": 13300
    },
    {
      "epoch": 8.34375,
      "grad_norm": 0.0001297736744163558,
      "learning_rate": 3.3125e-06,
      "loss": 0.0001,
      "step": 13350
    },
    {
      "epoch": 8.375,
      "grad_norm": 0.00037475055432878435,
      "learning_rate": 3.2500000000000002e-06,
      "loss": 0.0013,
      "step": 13400
    },
    {
      "epoch": 8.40625,
      "grad_norm": 0.002355320146307349,
      "learning_rate": 3.1875e-06,
      "loss": 0.0,
      "step": 13450
    },
    {
      "epoch": 8.4375,
      "grad_norm": 0.04060498997569084,
      "learning_rate": 3.125e-06,
      "loss": 0.0003,
      "step": 13500
    },
    {
      "epoch": 8.46875,
      "grad_norm": 0.0008049079333432019,
      "learning_rate": 3.0625000000000003e-06,
      "loss": 0.0001,
      "step": 13550
    },
    {
      "epoch": 8.5,
      "grad_norm": 0.000502321810927242,
      "learning_rate": 3e-06,
      "loss": 0.0001,
      "step": 13600
    },
    {
      "epoch": 8.53125,
      "grad_norm": 0.0013703498989343643,
      "learning_rate": 2.9375000000000003e-06,
      "loss": 0.0002,
      "step": 13650
    },
    {
      "epoch": 8.5625,
      "grad_norm": 0.0007042688084766269,
      "learning_rate": 2.875e-06,
      "loss": 0.0001,
      "step": 13700
    },
    {
      "epoch": 8.59375,
      "grad_norm": 0.00044678791891783476,
      "learning_rate": 2.8125e-06,
      "loss": 0.0,
      "step": 13750
    },
    {
      "epoch": 8.625,
      "grad_norm": 0.0002985789906233549,
      "learning_rate": 2.7500000000000004e-06,
      "loss": 0.0001,
      "step": 13800
    },
    {
      "epoch": 8.65625,
      "grad_norm": 0.02072269096970558,
      "learning_rate": 2.6875e-06,
      "loss": 0.0009,
      "step": 13850
    },
    {
      "epoch": 8.6875,
      "grad_norm": 0.0036943440791219473,
      "learning_rate": 2.6250000000000003e-06,
      "loss": 0.0001,
      "step": 13900
    },
    {
      "epoch": 8.71875,
      "grad_norm": 0.0014154253294691443,
      "learning_rate": 2.5625e-06,
      "loss": 0.0001,
      "step": 13950
    },
    {
      "epoch": 8.75,
      "grad_norm": 0.0010428972309455276,
      "learning_rate": 2.5e-06,
      "loss": 0.0002,
      "step": 14000
    },
    {
      "epoch": 8.78125,
      "grad_norm": 0.002171786967664957,
      "learning_rate": 2.4375e-06,
      "loss": 0.0001,
      "step": 14050
    },
    {
      "epoch": 8.8125,
      "grad_norm": 0.00010541714436840266,
      "learning_rate": 2.375e-06,
      "loss": 0.0002,
      "step": 14100
    },
    {
      "epoch": 8.84375,
      "grad_norm": 0.0004632589116226882,
      "learning_rate": 2.3125000000000003e-06,
      "loss": 0.0001,
      "step": 14150
    },
    {
      "epoch": 8.875,
      "grad_norm": 2.234018564224243,
      "learning_rate": 2.25e-06,
      "loss": 0.0017,
      "step": 14200
    },
    {
      "epoch": 8.90625,
      "grad_norm": 0.00015744817210361362,
      "learning_rate": 2.1875000000000002e-06,
      "loss": 0.0002,
      "step": 14250
    },
    {
      "epoch": 8.9375,
      "grad_norm": 0.009093938395380974,
      "learning_rate": 2.125e-06,
      "loss": 0.0,
      "step": 14300
    },
    {
      "epoch": 8.96875,
      "grad_norm": 0.0014436057535931468,
      "learning_rate": 2.0625e-06,
      "loss": 0.0004,
      "step": 14350
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.0002558327978476882,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.0003,
      "step": 14400
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 1.0,
      "eval_loss": 7.633459063072223e-06,
      "eval_runtime": 5.4484,
      "eval_samples_per_second": 587.33,
      "eval_steps_per_second": 73.416,
      "step": 14400
    },
    {
      "epoch": 9.03125,
      "grad_norm": 0.012192010879516602,
      "learning_rate": 1.9375e-06,
      "loss": 0.0001,
      "step": 14450
    },
    {
      "epoch": 9.0625,
      "grad_norm": 0.0002470821491442621,
      "learning_rate": 1.8750000000000003e-06,
      "loss": 0.0002,
      "step": 14500
    },
    {
      "epoch": 9.09375,
      "grad_norm": 0.0016928251134231687,
      "learning_rate": 1.8125e-06,
      "loss": 0.0001,
      "step": 14550
    },
    {
      "epoch": 9.125,
      "grad_norm": 6.318179657682776e-05,
      "learning_rate": 1.75e-06,
      "loss": 0.0,
      "step": 14600
    },
    {
      "epoch": 9.15625,
      "grad_norm": 0.0004185718426015228,
      "learning_rate": 1.6875000000000001e-06,
      "loss": 0.0001,
      "step": 14650
    },
    {
      "epoch": 9.1875,
      "grad_norm": 0.00016636322834528983,
      "learning_rate": 1.6250000000000001e-06,
      "loss": 0.0001,
      "step": 14700
    },
    {
      "epoch": 9.21875,
      "grad_norm": 0.0011637905845418572,
      "learning_rate": 1.5625e-06,
      "loss": 0.0001,
      "step": 14750
    },
    {
      "epoch": 9.25,
      "grad_norm": 0.00044162585982121527,
      "learning_rate": 1.5e-06,
      "loss": 0.0002,
      "step": 14800
    },
    {
      "epoch": 9.28125,
      "grad_norm": 0.00028103089425712824,
      "learning_rate": 1.4375e-06,
      "loss": 0.0005,
      "step": 14850
    },
    {
      "epoch": 9.3125,
      "grad_norm": 0.0006760659744031727,
      "learning_rate": 1.3750000000000002e-06,
      "loss": 0.0001,
      "step": 14900
    },
    {
      "epoch": 9.34375,
      "grad_norm": 0.00024601572658866644,
      "learning_rate": 1.3125000000000001e-06,
      "loss": 0.0002,
      "step": 14950
    },
    {
      "epoch": 9.375,
      "grad_norm": 0.03576350584626198,
      "learning_rate": 1.25e-06,
      "loss": 0.0006,
      "step": 15000
    },
    {
      "epoch": 9.40625,
      "grad_norm": 0.002624564105644822,
      "learning_rate": 1.1875e-06,
      "loss": 0.0001,
      "step": 15050
    },
    {
      "epoch": 9.4375,
      "grad_norm": 0.0012843675212934613,
      "learning_rate": 1.125e-06,
      "loss": 0.0001,
      "step": 15100
    },
    {
      "epoch": 9.46875,
      "grad_norm": 0.00012624006194528192,
      "learning_rate": 1.0625e-06,
      "loss": 0.0001,
      "step": 15150
    },
    {
      "epoch": 9.5,
      "grad_norm": 0.00045513067743740976,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 0.0007,
      "step": 15200
    },
    {
      "epoch": 9.53125,
      "grad_norm": 0.016253003850579262,
      "learning_rate": 9.375000000000001e-07,
      "loss": 0.0002,
      "step": 15250
    },
    {
      "epoch": 9.5625,
      "grad_norm": 0.0014554103836417198,
      "learning_rate": 8.75e-07,
      "loss": 0.0001,
      "step": 15300
    },
    {
      "epoch": 9.59375,
      "grad_norm": 0.0007002305937930942,
      "learning_rate": 8.125000000000001e-07,
      "loss": 0.0001,
      "step": 15350
    },
    {
      "epoch": 9.625,
      "grad_norm": 0.0007464796071872115,
      "learning_rate": 7.5e-07,
      "loss": 0.0,
      "step": 15400
    },
    {
      "epoch": 9.65625,
      "grad_norm": 0.000938378507271409,
      "learning_rate": 6.875000000000001e-07,
      "loss": 0.0001,
      "step": 15450
    },
    {
      "epoch": 9.6875,
      "grad_norm": 0.00018240889767184854,
      "learning_rate": 6.25e-07,
      "loss": 0.0001,
      "step": 15500
    },
    {
      "epoch": 9.71875,
      "grad_norm": 0.00022483528300654143,
      "learning_rate": 5.625e-07,
      "loss": 0.0001,
      "step": 15550
    },
    {
      "epoch": 9.75,
      "grad_norm": 0.0008017156505957246,
      "learning_rate": 5.000000000000001e-07,
      "loss": 0.0001,
      "step": 15600
    },
    {
      "epoch": 9.78125,
      "grad_norm": 0.3247051239013672,
      "learning_rate": 4.375e-07,
      "loss": 0.0003,
      "step": 15650
    },
    {
      "epoch": 9.8125,
      "grad_norm": 0.0016234491486102343,
      "learning_rate": 3.75e-07,
      "loss": 0.0001,
      "step": 15700
    },
    {
      "epoch": 9.84375,
      "grad_norm": 0.00010116386692970991,
      "learning_rate": 3.125e-07,
      "loss": 0.0001,
      "step": 15750
    },
    {
      "epoch": 9.875,
      "grad_norm": 0.00029139689286239445,
      "learning_rate": 2.5000000000000004e-07,
      "loss": 0.0002,
      "step": 15800
    },
    {
      "epoch": 9.90625,
      "grad_norm": 4.9604394007474184e-05,
      "learning_rate": 1.875e-07,
      "loss": 0.0,
      "step": 15850
    },
    {
      "epoch": 9.9375,
      "grad_norm": 0.10997569561004639,
      "learning_rate": 1.2500000000000002e-07,
      "loss": 0.0001,
      "step": 15900
    },
    {
      "epoch": 9.96875,
      "grad_norm": 0.5206490755081177,
      "learning_rate": 6.250000000000001e-08,
      "loss": 0.0002,
      "step": 15950
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.00198925263248384,
      "learning_rate": 0.0,
      "loss": 0.0001,
      "step": 16000
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 1.0,
      "eval_loss": 7.092493433447089e-06,
      "eval_runtime": 5.4385,
      "eval_samples_per_second": 588.402,
      "eval_steps_per_second": 73.55,
      "step": 16000
    }
  ],
  "logging_steps": 50,
  "max_steps": 16000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4253527965696000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
